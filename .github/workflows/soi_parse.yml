name: SOI Monthly Parse Run

concurrency: 
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

on: 
  schedule:
    - cron: 0 5 1 * *
  workflow_dispatch:


jobs:
  Run-SOI-Parsing:
    timeout-minutes: 600
    runs-on: ubuntu-22.04
    steps:
      - name: Setup swap
        uses: pierotofy/set-swap-space@v1.0
        with:
          swap-size-gb: 12
      - uses: actions/checkout@v3
      - uses: docker/setup-buildx-action@v2
      - name: Build Image
        uses: docker/build-push-action@v3
        with:
          context: maps/SOI
          load: true
          file: maps/SOI/Dockerfile.parse
          build-args: |
            build_type=final
          tags: soi-parse:latest
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Authenticate with GCP
        run: |
          echo ${{ secrets.GCP_AUTH }} | base64 -d > gauth.json
          gcloud auth activate-service-account --key-file=gauth.json

      - name: Check for work
        id: work
        run: |
          if [[ "$(gsutil ls gs://soi_data/to_parse.txt 2>/dev/null)" == "" ]]; then
            echo "AVAILABLE=false" >> $GITHUB_OUTPUT
          else
            mkdir -p data
            gsutil -m cp gs://soi_data/to_parse.txt data/to_parse.txt
            echo "AVAILABLE=true" >> $GITHUB_OUTPUT
          fi

      - name: Get current date
        run: echo "date=$(date +'%d%b%Y')" >> $GITHUB_OUTPUT
        id: date

      - name: Restore parse run data from cache
        uses: ramSeraph/cache-always@v0.0.1
        with:
          path: |
            data/index.geojson
            data/raw/
            export/gtiffs/
          key:  soi-gcs-parse-v4-${{ steps.date.outputs.date }}-${{ github.run_number }}-${{ github.run_attempt }}
          restore-keys: |
            soi-gcs-parse-v4-${{ steps.date.outputs.date }}-${{ github.run_number }}-
            soi-gcs-parse-v4-${{ steps.date.outputs.date }}-


      - name: Parse SOI sheets
        if: steps.work.outputs.AVAILABLE == 'true'
        run: |
          gsutil -m cp gs://soi_data/raw/SOI_FONTS.zip data/raw/SOI_FONTS.zip
          gsutil -m cp gs://soi_data/index.geojson data/index.geojson
          find data
          find export || true
          cat data/to_parse.txt | xargs -I {} bash -c "[[ -e {} ]] || echo {}" > data/to_download.txt
          cat data/to_download.txt | cut -d"/" -f2- | xargs -I {} gsutil -m cp gs://soi_data/{} data/{}
          docker run -d --name dup-checker -v $(pwd):/code -w /code soi-parse:latest maps/SOI/check_duplicates.py data/to_parse.txt
          docker logs -f dup-checker
          exit_code=$(docker inspect dup-checker --format='{{.State.ExitCode}}')
          if [[ "$exit_code" != "0" ]]; then
            echo "exit_code: $exit_code"
            exit 1
          fi
          mkdir -p export/gtiffs/
          docker run -d --name parser -v $(pwd):/code -w /code -e FROM_LIST=data/to_parse.txt --memory="6g" --memory-swap="-1" soi-parse maps/SOI/parse.py
          docker logs -f parser
          exit_code=$(docker inspect parser --format='{{.State.ExitCode}}')
          if [[ "$exit_code" != "0" ]]; then
            echo "exit_code: $exit_code"
            exit 1
          fi
          gsutil rm gs://soi_data/to_parse.txt
          gsutil -m cp -r export/gtiffs/*.tif gs://soi_data/export/gtiffs/
          ls export/gtiffs/*.tif | cut -d"/" -f3 | cut -d"." -f1 > data/to_retile.txt
          gsutil cp data/to_retile.txt gs://soi_data/to_retile.txt
          rm -rf data/raw/* || true
          rm -rf export/gtiffs/* || true
        timeout-minutes: 600
 
      - name: Update lists
        if: steps.work.outputs.AVAILABLE == 'true'
        run: |
          maps/SOI/generate_lists.sh

      - name: Check for retile work
        id: retile_work
        run: |
          if [[ "$(gsutil ls gs://soi_data/to_retile.txt 2>/dev/null)" == "" ]]; then
            echo "AVAILABLE=false" >> $GITHUB_OUTPUT
          else
            mkdir -p data
            gsutil -m cp gs://soi_data/to_retile.txt data/to_retile.txt
            gsutil -m cp gs://soi_data/index.geojson data/index.geojson
            echo "AVAILABLE=true" >> $GITHUB_OUTPUT
          fi
      - name: Restore run data from cache
        uses: ramSeraph/cache-always@v0.0.1
        with:
          path: |
            staging/
            export/
            !export/pmtiles/*
          key:  soi-gcs-v5-${{ steps.date.outputs.date }}-${{ github.run_number }}-${{ github.run_attempt }}
          restore-keys: |
            soi-gcs-v5-${{ steps.date.outputs.date }}-${{ github.run_number }}-
            soi-gcs-v5-${{ steps.date.outputs.date }}-

      - name: Download pmtiles
        id: download-pmtiles
        if: steps.retile_work.outputs.AVAILABLE == 'true'
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          ls staging || true
          if [[ -e staging/all_done ]]; then
            echo "download already done.. shortcircuiting"
            exit 0
          fi
          source .github/scripts/rfuncs.sh
          mkdir -p export/pmtiles
          echo "getting release id"
          echo "repo=$GITHUB_REPOSITORY"
          release_id="$(get_release_id soi-latest)"
          echo "release id is $release_id"
          cat err_file.txt
          download_release_assets $release_id export/pmtiles
          mkdir -p staging

      - name: Retile sheets
        id: retile-sheets
        if: steps.retile_work.outputs.AVAILABLE == 'true'
        run: |
          if [[ -e staging/retiling_done ]]; then
            exit 0
          fi
          mkdir -p export/tiles/
          mkdir -p staging/tiles/
          mkdir -p staging/pmtiles/
          docker run -d --name retiler -v $(pwd):/code -w /code -e GOOGLE_APPLICATION_CREDENTIALS=gauth.json soi-parse maps/SOI/retile.py data/to_retile.txt
          docker logs -f retiler
          exit_code=$(docker inspect retiler --format='{{.State.ExitCode}}')
          if [[ "$exit_code" != "0" ]]; then
            echo "exit_code: $exit_code"
            exit 1
          fi
          touch staging/retiling_done
        timeout-minutes: 600

      - name: Partition pmtiles
        id: partition-pmtiles
        if: steps.retile_work.outputs.AVAILABLE == 'true'
        run: |
          if [[ -e staging/all_done ]]; then
            exit 0
          fi
          docker run -d --name partitioner -v $(pwd):/code -w /code soi-parse maps/SOI/partition.py
          docker logs -f partitioner
          exit_code=$(docker inspect partitioner --format='{{.State.ExitCode}}')
          if [[ "$exit_code" != "0" ]]; then
            echo "exit_code: $exit_code"
            exit 1
          fi
          rm -rf export/*
          staging_files=$(find staging/pmtiles -type f)
          echo "release_files<<EOF" >> $GITHUB_OUTPUT
          echo "$staging_files" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          touch staging/all_done
          

      - name: Push pmtiles
        env:
          GH_TOKEN: ${{ github.token }}
        id: push-pmtiles
        if: steps.retile_work.outputs.AVAILABLE == 'true'
        uses: ./.github/actions/releaser
        with:
          name: "SOI Open Series Maps"
          tag_name: soi-latest
          assets: ${{ steps.partition-pmtiles.outputs.release-files }} 
          body: "SOI Open Series Maps as partitioned PMTiles."
          gh_token: ${{ secrets.github_token }}

      - name: Cleanup
        if: steps.retile_work.outputs.AVAILABLE == 'true'
        run: |
          rm -rf staging/*
          gsutil rm gs://soi_data/to_retile.txt
 

  SOI-Parse-Failure-Notify:
    needs: [Run-SOI-Parsing]
    if: always() && needs.Run-SOI-Parsing.result == 'failure'
    uses: ./.github/workflows/common-pb-alert.yml
    secrets: inherit
    with:
      title: "SOI Parse Run Failed"
      which-run: "self"
