name: SOI Weekly Unavailable Pull Run

concurrency: 
  group: ${{ github.workflow }}
  cancel-in-progress: true

on: 
  schedule:
    - cron: '0 0 * * 6'
  workflow_dispatch:


jobs:
  Run-SOI-Extraction:
    timeout-minutes: 600
    runs-on: ubuntu-latest
    env:
      GH_TOKEN: ${{ github.token }}
    steps:
      - uses: actions/checkout@v4.1.7

      - name: Install uv
        uses: astral-sh/setup-uv@v5
        with:
          enable-cache: true
          cache-dependency-glob: maps/SOI/scrape.py.lock

      - name: Restore tesseract models from cache
        uses: actions/cache/restore@v4
        with:
          path: 'maps/SOI/data/captcha/models/'
          key:  'SOI-tesseract-models-v2'
        id: models-cache

      - name: Install packages
        run: |
          sudo apt-get update
          sudo apt-get install -y tesseract-ocr

      - name: Download tesseract models from github releases
        if: ${{ steps.models-cache.outputs.cache-hit != 'true' }}
        run: |
          cd maps/SOI
          mkdir -p data/captcha/models/
          util/download_captcha_models.sh data/captcha/models

      - name: Save tesseract models to cache
        if: ${{ steps.models-cache.outputs.cache-hit != 'true' }}
        uses: actions/cache/save@v4
        with:
          path: 'maps/SOI/data/captcha/models/'
          key:  'SOI-tesseract-models-v2'

      - name: Restore ancillary files from cache
        uses: actions/cache/restore@v4
        with:
          path: |
            maps/SOI/data/index.geojson
            maps/SOI/data/raw/SOI_FONTS.zip
          key: 'SOI-scrape-basefiles-v1'
        id: base-files-cache
            
      - name: Download Ancillary data
        if: ${{ steps.base-files-cache.outputs.cache-hit != 'true' }}
        run: |
          cd maps/SOI
          mkdir -p data/raw
          [[ -f data/index.geojson ]] || wget -P data https://github.com/ramSeraph/opendata/releases/download/soi-ancillary/index.geojson
          [[ -f data/raw/SOI_FONTS.zip ]] || wget -P data https://github.com/ramSeraph/opendata/releases/download/soi-ancillary/SOI_FONTS.zip

      - name: Save ancillary files to cache
        if: ${{ steps.base-files-cache.outputs.cache-hit != 'true' }}
        uses: actions/cache/save@v4
        with:
          path: |
            maps/SOI/data/index.geojson
            maps/SOI/data/raw/SOI_FONTS.zip
          key: 'SOI-scrape-basefiles-v1'

      - name: Get current date
        run: echo "date=$(date +'%d%b%Y')" >> $GITHUB_OUTPUT
        id: date

      - name: Restore prev login workspace
        uses: actions/cache/restore@v4
        with:
          path: |
            maps/SOI/data/cookies/
            maps/SOI/data/tried_users.txt
          key:  SOI-data-ua-login-v3-${{ steps.date.outputs.date }}-${{ github.run_number }}-${{ github.run_attempt }}
          restore-keys: |
            SOI-data-ua-login-v3-${{ steps.date.outputs.date }}-${{ github.run_number }}-
            SOI-data-ua-login-v3-${{ steps.date.outputs.date }}-

      - name: Restore prev data workspace
        uses: actions/cache/restore@v4
        with:
          path: |
            maps/SOI/data/raw/*.pdf
            maps/SOI/data/raw/*.unavailable
          key:  SOI-data-ua-raw-v3-${{ github.run_number }}-${{ github.run_attempt }}
          restore-keys: |
            SOI-data-ua-raw-v3-${{ github.run_number }}-
            SOI-data-ua-raw-v3-

      - name: Bring up the proxy
        id: setup-proxy
        uses: ramSeraph/gcp-simple-proxy-action/start@v0.0.1
        with:
          gcp-project: ${{ secrets.GCP_PROJECT }}
          gcp-zone: asia-south1-a
          gcp-credentials: ${{ secrets.GCP_AUTH }}

      # scrape things
      - name: Download SOI data
        run: |
          cd maps/SOI
          mkdir -p data/raw

          ip_address="${{ steps.setup-proxy.outputs.ip_address }}"

          echo "${{ secrets.SOI_USERS }}" | base64 -d > data/users.json

          wget https://github.com/ramSeraph/opendata/releases/download/soi-pdfs/list.txt
          cat list.txt | cut -d" " -f2 | xargs -I {} echo {}.pdf > data/files_done.txt

          PROXY_URL="http://${ip_address}:80" PB_TOKEN="${{ secrets.PB_TOKEN }}" uv run scrape.py -u -p -i -r 25
        timeout-minutes: 180

      - name: Bring down the proxy
        if: always()
        uses: ramSeraph/gcp-simple-proxy-action/stop@v0.0.1
        with:
          gcp-project: ${{ secrets.GCP_PROJECT }}
          gcp-zone: asia-south1-a
          gcp-credentials: ${{ secrets.GCP_AUTH }}
          gcp-instance-name: ${{ steps.setup-proxy.outputs.instance_name }}

      - name: Upload raw files to github releases
        run: |
          cd maps/SOI
          ls data/raw/*.pdf > downloaded.txt || touch downloaded.txt
          cat downloaded.txt
          cat downloaded.txt | xargs -I {} gh release upload soi-pdfs {}
          rm -rf data/raw/*.pdf || true
          rm -rf data/raw/*.unavailable || true
          rm -rf data/cookies || true
          rm -rf data/tried_users.txt || true
          rm downloaded.txt

      - name: Update lists
        run: |
          cd maps/SOI
          util/generate_lists.sh pdfs

      - name: Save prev data workspace
        if: always()
        uses: actions/cache/save@v4
        with:
          path: |
            maps/SOI/data/raw/*.pdf
            maps/SOI/data/raw/*.unavailable
          key:  SOI-data-ua-raw-v3-${{ github.run_number }}-${{ github.run_attempt }}

      - name: Save prev login workspace
        if: always()
        uses: actions/cache/save@v4
        with:
          path: |
            maps/SOI/data/cookies/
            maps/SOI/data/tried_users.txt
          key:  SOI-data-ua-login-v3-${{ steps.date.outputs.date }}-${{ github.run_number }}-${{ github.run_attempt }}


  SOI-Extraction-Failure-Notify:
    needs: [Run-SOI-Extraction]
    if: always() && needs.Run-SOI-Extraction.result == 'failure'
    uses: ./.github/workflows/common-pb-alert.yml
    secrets: inherit
    with:
      title: "SOI Extraction Run Failed"
      which-run: "self"
